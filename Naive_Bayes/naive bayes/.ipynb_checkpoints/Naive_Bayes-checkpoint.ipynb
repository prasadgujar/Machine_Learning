{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #Input: X - features of a trainset\n",
    "    #       y - labels of a trainset\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        self.no_of_classes = np.max(self.y_train) + 1\n",
    "     \n",
    "        \n",
    "    #This is our function to calculate all nodes/samples in our radius    \n",
    "    def euclidianDistance(self, Xtest, Xtrain):\n",
    "        return np.sqrt(np.sum(np.power((Xtest - Xtrain), 2)))\n",
    "    \n",
    "       \n",
    "    #our main function is predict\n",
    "    #All calculation is done by using our test or new samples\n",
    "    #There are 4 steps to be performed:\n",
    "    # 1. calculate Prior probability. Ex. P(A) = No_of_elements_of_one_class / total_no_of_samples\n",
    "    # 2. calculate Margin probability P(X) = No_of_elements_in_radius / total_no_of_samples\n",
    "    # 3. calculate Likeliyhood (P(X|A) = No_of_elements_of_current_class / total_no_of_samples\n",
    "    # 4. calculate Posterior probability: P(A|X) = (P(X|A) * P(A)) / P(X)\n",
    "    # NOTE: Do these steps for all clases in dataset!\n",
    "    #\n",
    "    #Inputs: X - test dataset\n",
    "    #       radius - this parameter is how big circle is going to be around our new datapoint, default = 2\n",
    "    def predict(self, X, radius=0.4):   \n",
    "        pred = []\n",
    "        \n",
    "        #Creating list of numbers of elements for each class in trainset\n",
    "        members_of_class = []\n",
    "        for i in range(self.no_of_classes):\n",
    "            counter = 0\n",
    "            for j in range(len(self.y_train)):\n",
    "                if self.y_train[j] == i:\n",
    "                    counter += 1\n",
    "            members_of_class.append(counter)\n",
    "        \n",
    "        #Entering the process of prediction\n",
    "        for t in range(len(X)):\n",
    "            #Creating empty list for every class probability\n",
    "            prob_of_classes = []\n",
    "            #looping through each class in dataset\n",
    "            for i in range(self.no_of_classes):\n",
    "                \n",
    "                #1. step > Prior probability P(class) = no_of_elements_of_that_class/total_no_of_elements\n",
    "                prior_prob = members_of_class[i]/len(self.y_train)\n",
    "\n",
    "                #2. step > Margin probability P(X) = no_of_elements_in_radius/total_no_of_elements\n",
    "                #NOTE: In the same loop collecting infromation for 3. step as well\n",
    "                \n",
    "                inRadius_no = 0\n",
    "                #counter for how many points are from the current class in circle\n",
    "                inRadius_no_current_class = 0\n",
    "                \n",
    "                for j in range(len(self.X_train)):\n",
    "                    if self.euclidianDistance(X[t], self.X_train[j]) < radius:\n",
    "                        inRadius_no += 1\n",
    "                        if self.y_train[j] == i:\n",
    "                            inRadius_no_current_class += 1\n",
    "                \n",
    "                #Computing, margin probability\n",
    "                margin_prob = inRadius_no/len(self.X_train)\n",
    "                \n",
    "                #3. step > Likelihood P(X|current_class) = no_of_elements_in_circle_of_current_class/total_no_of_elements\n",
    "                likelihood = inRadius_no_current_class/len(self.X_train)\n",
    "                \n",
    "                #4. step > Posterial Probability > formula from Bayes theorem: P(current_class | X) = (likelihood*prior_prob)/margin_prob\n",
    "                post_prob = (likelihood * prior_prob)/margin_prob\n",
    "                prob_of_classes.append(post_prob)\n",
    "            \n",
    "            #Getting index of the biggest element (class with the biggest probability)\n",
    "            pred.append(np.argmax(prob_of_classes))\n",
    "                \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_tes, y_pred):\n",
    "    correct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_tes[i] == y_pred[i]):\n",
    "            correct += 1\n",
    "    return (correct/len(y_tes))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Breast Cancer dataset\n",
    "def breastCancerTest():\n",
    "    # Importing the dataset\n",
    "    dataset = pd.read_csv('breastCancer.csv')\n",
    "    dataset.replace('?', 0, inplace=True)\n",
    "    dataset = dataset.applymap(np.int64)\n",
    "    X = dataset.iloc[:, 1:-1].values    \n",
    "    y = dataset.iloc[:, -1].values\n",
    "    #This part is necessery beacuse of NUMBER of features part of algo\n",
    "    #and in this dataset classes are marked with 2 and 4\n",
    "    y_new = []\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 2:\n",
    "            y_new.append(0)\n",
    "        else:\n",
    "            y_new.append(1)\n",
    "    y_new = np.array(y_new)\n",
    "\n",
    "\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "    \n",
    "    #Testing my Naive Bayes Classifier\n",
    "    NB = NaiveBayesClassifier()\n",
    "    NB.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = NB.predict(X_test, radius=8)\n",
    "    \n",
    "    #sklearn\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    NB_sk = GaussianNB()\n",
    "    NB_sk.fit(X_train, y_train)\n",
    "    \n",
    "    sk_pred = NB_sk.predict(X_test)\n",
    "     \n",
    "    \n",
    "    print(\"Accuracy for my Naive Bayes Classifier: \", accuracy(y_test, y_pred), \"%\")\n",
    "    print(\"Accuracy for sklearn Naive Bayes Classifier: \",accuracy(y_test, sk_pred), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for my Naive Bayes Classifier:  96.57142857142857 %\n",
      "Accuracy for sklearn Naive Bayes Classifier:  95.42857142857143 %\n"
     ]
    }
   ],
   "source": [
    "breastCancerTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
